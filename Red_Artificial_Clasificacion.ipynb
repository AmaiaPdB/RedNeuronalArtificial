{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Red_Artificial_Clasificacion.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# INTRODUCCIÓN:\n",
        "\n",
        "## Objetivo: que la red distinga diferentes tipos de zapato.\n",
        "## Si queremos que la red distinga diferentes tipos zapatos, si le enseñamos pocos, a lo mejor coincide que todas las sandalias que le eseñamos son rojas \n",
        "## e interpreta que un zapato rojo es una sandalia (el llamado overfitting). Para que esto no ocurra y aprenda como es cada tipo de zapato, habrá que enseñarle \n",
        "## muchos zapatos de diferentes colores, tipos, formas...\n",
        "\n",
        "## Utilizaremos Fashion MNIST de TensorFlow, un dataset de ropa con 70.000 imágenes en escala de grises agrupadas en 10 categorías de 7.000 imágenes.\n",
        "## El dataset se divide en un set de entrenamiento o train_images con sus etiquetas train_labels (60.000 imágenes) y en un set de test o test_images \n",
        "## con sus etiquetas test_labels (10.000 imágenes). Las etiquetas son números por dos razones: mejor compresión por un sistema computacional \n",
        "## y evitar sesgos que pueda introducir un idioma.\n",
        "\n",
        "## Las imágenes son pequeñas, de 28x28 píxeles (matriz de 28x28), lo cual hará que el ordenador las procese más rápido que si habláramos de imágenes médicas.\n",
        "## La capa de entrada de la red tendrá que tener 28x28 neuronas, una por píxel\n",
        "## El modelo funcionará porque en la imagen solo tenemos el objeto que nos iteresa, siempre en la misma posición (centrado), las imágenes son del mismo tamaño, etc. \n",
        "## Si no, necesitaríamos una red que extrajera los contenidos de la imagen más que analizar la imagen como un todo, es decir, no nos serviría una red neuronal profunda, sino que haría falta una CNN.\n"
      ],
      "metadata": {
        "id": "8ODxDLvz4aBP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PROGRAMACIÓN:\n",
        "\n",
        "## 1º: Importar las librerías necesarias y el dataset Fashion MNIST."
      ],
      "metadata": {
        "id": "aftgp-524efz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpdOGkU833_T"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Podemos ver los elementos que queramos de las imágenes importadas. \n",
        "## En el ejemplo de acontinuación vemos la imagen 0 y su etiqueta.\n",
        "## Estos sistemas ven las imágenes como arrays, es decir, como una matríz de 28 filas y 28 columnas.\n",
        "\n"
      ],
      "metadata": {
        "id": "iyAt8Gtb5l3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print('La etiqueta de la imagen escogida es: ', training_labels[0])   #Vemos la etiqueta.\n",
        "print(training_images[0])                                             #Vemos la imagen como una matriz de números.\n",
        "plt.imshow(training_images[0])                                        #La imagen como la vemos nosotros. \n",
        "\n"
      ],
      "metadata": {
        "id": "JkY6c_Ed5kGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2º: Normalizar las imágenes.\n",
        "\n",
        "## Vemos que los pixels de la matriz toman valores entre 0 y 255, es decir, pueden tomar 256 grises distintos, lo que significa que la profundidad es de \n",
        "## 8 bits (2^8 es 256). Ahora tendremos que NORMALIZAR el dataset. Se ha demostrado que las redes funcionan mejor manejando valores entre 0 y 1, \n",
        "## entonces nos interesaría que los pixels tomarán valores entre 0 y 1, para lo cual no tenemos más que dividir por el número más alto que pueden tomar, \n",
        "## en este caso 255. Así, el píxel que tomaba el valor 0 seguirá tomando el valor 0, el píxel que tomaba el 255 ahora tomará el 1, el que tomaba el 10 \n",
        "## ahora 10/255 y así con todos."
      ],
      "metadata": {
        "id": "3gGQanbp5dtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_images  = training_images / 255.0\n",
        "test_images = test_images / 255.0\n"
      ],
      "metadata": {
        "id": "t11xTXmj5f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3º: Diseñar la arquitectura del modelo.\n",
        "\n",
        "## Es recomendable comenzar el diseño por la capa de entrada y la de salida, dedicando especial atención a cómo son los inputs y outputs que tenemos y \n",
        "## necesitamos, respectivamente. \n",
        "## En este ejemplo, metemos un tamaño de entrada de 28x28 píxels, por lo que necesitaremos un número de neuronas en la primera capa, la capa de entrada, \n",
        "## de 28x28. En cuanto a la capa de salida, si clasificaremos en 10 clases diferentes, necesitaremos que tenga 10 neuronas."
      ],
      "metadata": {
        "id": "TKeLLWeg5W26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                    tf.keras.layers.Dense(128, activation='relu'), \n",
        "                                    tf.keras.layers.Dense(10, activation='softmax')])\n",
        "                                    \n",
        "\n"
      ],
      "metadata": {
        "id": "tE0RDFNW5WMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4º: Compilar el modelo. \n",
        "\n",
        "## Programamos la función de error o pérdida y la función de optimización o aprendizaje.\n",
        "## Fijamos la variable en la que nos fijaremos. En este caso, la \"accuracy\".\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WE3yu1H55Ogf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(), loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "6QZfu4Yq5RbM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5º: Entrenar el modelo.\n",
        "\n",
        "## Consiste en \"ajustar los ejemplos conocidos a sus etiquetas\", de ahí que la función de entrenamiento se llame fit. Llamamos a la función fit y le pasamos \n",
        "## de argumentos: nuestro dataset de entrenamiento, nuestras etiquetas, y nuestras épocas (el número de veces que revisará el dataset e irá aprendiendo).\n"
      ],
      "metadata": {
        "id": "4Amv7x_-4-gD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.fit(training_images, training_labels, epochs=20)"
      ],
      "metadata": {
        "id": "HVQ5YqZk49qS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6º: Testar el modelo con el set de test.\n",
        "\n",
        "## Calcularemos la ACCURACY con las imágenes de test. \n",
        "\n"
      ],
      "metadata": {
        "id": "qsx34BEA43tn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JMPaRsqO4vqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## En nuestro caso, nos devolvió una \"accuracy\" de 0.8839."
      ],
      "metadata": {
        "id": "Nk9DUc7u4zMC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7º: Introducir nuevos ejemplos.\n",
        "\n",
        "## Se pueden hacer nuevas predicciones prediction1, prediction 2... llamando al módulo model.predict e introduciendo como argumento la nueva imagen.\n",
        "prediction = model.predict(newimage)"
      ],
      "metadata": {
        "id": "-SBH9TyD4sqT"
      }
    }
  ]
}